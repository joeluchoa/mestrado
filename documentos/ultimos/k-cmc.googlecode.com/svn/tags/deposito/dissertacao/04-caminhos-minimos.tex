%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  CAPÍTULO. CAMINHO MÏNIMO 
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\chapter{Caminhos mínimos e Dijkstra}
\label{cap:problema-CM}

Estão descritos neste capítulo os elementos básicos que envolvem o
problema do caminho mínimo, tais como função-custo, função-potencial, 
função-predecessor, critério de otimalidade e o celebrado algoritmo de 
Edsger Wybe Dijkstra~\cite{dijkstra59:note} que resolve o problema do caminho mínimo. 
A referência básica para este capítulo são as notas de aula de Paulo
Feofiloff~\cite{pf:fluxos} e a dissertação de Shigueo Isotani~\cite{shigueo}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: Descrição
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Descrição}
\label{sec:problema-descricao-CM}

%
% função-custo
%

Uma \defi{função-custo}\index{função@função!custo}\index{custo!funcao@função} 
em $(V,A)$ é uma função de $A$ em $\NonnegInt$. Se $c$ é uma função-custo 
em $(V,A)$ e $uv$ estiver em $A$, então
$c(uv)$ será o valor de $c$ em $uv$. 
%
% Custo de um passeio e passeio de custo mínimo.
% 
Se $P$ for um caminho em um grafo $(V,A)$ e $c$ uma função-custo, 
então $c(P)$ é o \defi{custo do caminho}\index{custo!caminho} $P$%
\index{custo!caminho}, ou seja, $c(P)$ é o soma dos custos
de todos os arcos em $P$. 
 Um caminho $P$ tem \defi{custo mínimo} se
$c(P) \leq c(P')$ para todo caminho $P'$ com o mesmo início e término
que~$P$ (figura~\ref{fig:custo1}). 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[hbp]
\begin{center}
  \psfrag{0}{\red $1$}
  \psfrag{1}{\red $1$}
  \psfrag{2}{\red $2$}
  \psfrag{3}{\red $3$}
  \psfrag{4}{\red $4$}
  \psfrag{5}{\red $5$}
  \psfrag{6}{\red $6$}
  \psfrag{7}{\red $7$}
  \psfrag{8}{\red $8$}
  \psfrag{9}{\red $9$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{$\black v$}
  \psfrag{u}{$\black u$}
  \psfrag{w}{$\black w$}
  \psfrag{z}{$\black z$}
  \psfrag{(a)}{(a)}
  \psfrag{(b)}{(b)}
  \includegraphics[scale=0.9]{./figs/caminho-custo2.eps}
  \quad \quad
  \includegraphics[scale=0.9]{./figs/caminho-custo3.eps}
 \caption{\label{fig:custo1} Um grafo com custos nos arcos. 
   O custo do caminho $\seq{s,u,w,z,t}$ é 14. À direita o  caminho de
custo mínimo $\seq{s,w,t}$ está em destaque.}
 \end{center}
\end{figure}

Como a nossa função-custo é não-negativa, 
então no grafo há sempre um passeio de custo mínimo que é uma caminho. 
Por esta razão, um passeio de custo mínimo 
é simplesmente chamado de \defi{caminho mínimo}\index{caminho!minimo@mínimo}.



%Uma \defi{função comprimento}\index{funcao@@função!comprimento} %
%\index{comprimento!funcao@@função} em
%$(V,A)$ é uma função de $A$ em $\NonnegInt$. Se $c$ é uma função
%comprimento em $(V,A)$ e $uv$ está em $A$, então, denotaremos por
%$c(u,v)$ o valor de $c$ em $uv$. 


Se $(V,A)$ é um grafo simétrico e $c$ é 
uma função comprimento em $(V,A)$, então $c$ é 
\defi{simétrica}\index{funcao@@função!comprimento simétrica} se
$c(uv) = c(vu)$ para todo arco $uv$. 
%%%% CZAO
O \defi{maior custo}\index{maior
  custo} de um arco será denotado por $C$\mar{$C$}, ou seja, 
$C := \max\{c(uv) \tq uv \in A \}$.
No grafo da figura~\ref{fig:custo1} temos que $C=7$.

%%% Comprimento de um passeio e passei de comprimento minimo.
%% Se $P$ é um passeio em um grafo $(V,A)$ e $c$ é uma função comprimento, 
%% denotaremos por $c(P)$ o \defi{comprimento do caminho} $P$%
%% \index{comprimento!do caminho}, ou seja, $c(P)$ é o somatório dos comprimentos
%% de todos os arcos em $P$.  Um passeio $P$ tem \defi{comprimento mínimo} se
%% $c(P) \leq c(P')$ para todo passeio $P'$ que tenha o mesmo início e término
%% que $P$.  

A \defi{distância}\index{distancia@@distância} de um vértice $s$ a um
vértice $t$ é o menor custo de um caminho de $s$ a~$t$. 
A distância de $s$ a $t$ em relação a $c$ será denotada por 
$\distc{s,t}$\index{$\distc{s,t}$}\mar{$\distc{s,t}$}, ou simplesmente, 
quando a função
custo estiver subentendida, por
$\dist{s,t}$\index{$\dist{s,t}$}\mar{$\dist{s,t}$}
denota a distância de $s$ a $t$. 
Na figura~\ref{fig:custo1} a distância de $s$ a $t$ é 4.
 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  DEFINIÇÃO
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
%\section{Definição do problema}
%
% Problema dos menores caminhos 
% 
 
Um problema fundamental em otimização combinatória que tem um papel de
destaque nesta dissertação é o 
\defi{problema do caminho mínimo}, denotado por
\PCM:\index{problema!do caminho mínimo@do caminho mínimo}
 \begin{quote}
   \textbf{Problema} \PCM$(V,A,c,s,t)$: 
   \index{\PCM}\mar{\PCM}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   Dado um grafo $(V,A)$, uma função
   custo~$c$ e dois vértice $s$ e $t$, 
   encontrar um caminho de custo mínimo 
   de $s$ a~$t$.
 \end{quote}
Na literatura essa versão é conhecida como \textit{single-pair
  shortest path problem}\index{single-pair shortest path@single-source
  shortest path}.  O celebrado algoritmo de Edsger Wybe
Dijkstra~\cite{dijkstra59:note}, apresentado na
seção~\ref{sec:dijkstra}, resolve o problema do caminho mínimo.

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: FUNÇÕES POTENCIAL
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\section{Funções potenciais e critério de otimalidade}
\label{sec:criterio-otimalidade}

Como é possível provar que um dado caminho de um vértice 
$s$ a um vértice $t$ é de custo mínimo?
Algoritmos para o \PCM{} fornecem certificados de otimalidade de 
suas respostas. Esses certificados vêm de dualidade de programação linear.
De fato, o seguinte programa linear, que chamamos de primal, é uma
relaxação do pro\-ble\-ma do caminho mínimo: encontrar um vetor
$x$ indexado por $A$ que
\begin{eqnarray*}
\begin{array}{rrlrl}
\mbox{minimize} & cx \hfill\\
\mbox{sob as restrições} & x(\sai(s)) - x(\entra(s)) \hfill & = & 1 \\
& x(\sai(t)) -  x(\entra(t)) \hfill & = & -1 \\
& x(\sai(v)) - x(\entra(v)) \hfill & = & 0 & \mbox{para cada $v$
em $V \setminus \{s,t\}$} \\
& x[uv] & \geq & 0 & \mbox{para cada $uv$ em $A$.}
\end{array}
\end{eqnarray*}

De fato, cada vetor característico de um caminho se $s$ a $t$ é
uma solução viável do problema primal.

O respectivo problema dual consiste em encontrar um vetor $y$
indexado por $V$ que
\begin{eqnarray*}
\begin{array}{rllll}
\mbox{maximize} & y(t)-y(s) \\
\mbox{sob as restrições} & y(v) -  y(u) & \leq & c(uv) &
\mbox{para cada $uv$ em $A$.}
\end{array}
\end{eqnarray*}



Se um vértice $t$ não
é acessível a partir de $s$ um algoritmo pode, para comprovar este fato,
devolver uma parte $S$ de $V$ tal que $s \in S$, $t \not\in S$ e não existe
$uv$ com $u$ em $S$ e $v$ em $V\setminus S$, ou seja $A(S)= \emptyset$. Este
seria um certificado combinatória de \defi{não-acessibilidade} de $t$ por $s$.
Entretanto, os certificados fornecidos pelos algoritmos, baseados em funções
potencial, serão um atestado compacto para certificar ambos: a otimalidade
dos caminhos fornecidos, e a não acessabilidade de alguns vértices por $s$.

Uma \defi{função-potencial}\index{funcao@@função!potencial}%
\index{potencial!funcao@@função} é uma função de $V$ em $\Int$.
Se $y$ é uma função-potencial e $c$ é uma função-custo, 
então, dizemos que $y$ é um \defi{$c$-potencial}\index{c-potencial@$c$-potencial}
se 
 \begin{center}
   $y(v) - y(u) \leq c(uv)$ para cada arco $uv$ em $A$ (figura~\ref{fig:potencial}).
 \end{center}


\begin{figure}
\begin{center}
  \psfrag{0}{\red $1$}
  \psfrag{1}{\red $1$}
  \psfrag{2}{\red $1$}
  \psfrag{3}{\red $1$}
  \psfrag{4}{\red $2$}
  \psfrag{5}{\red $2$}
  \psfrag{6}{\red $6$}
  \psfrag{7}{\red $7$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{$\black v$}
  \psfrag{u}{$\black u$}
  \psfrag{w}{$\black w$}
  \psfrag{z}{$\black z$}
  \psfrag{c}{$c$}
  \psfrag{ps}{\blue $2$}
  \psfrag{pt}{\blue $3$}
  \psfrag{pv}{\blue $4$}
  \psfrag{pu}{\blue $4$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=1]{./figs/c-potencial.eps}
\end{center}
\caption{\label{fig:potencial} (a) Um grafo com custos nos arcos. 
   e um c-potencial. Os números próximos aos vértices são os seu ponteciais.}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Se $y$ respeita $c$ em $A$ então diz-se que $y$ é 
%\defi{viável}\index{funcao@@função!potencial viavel@@potencial viável}. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Limitantes inferiores para custo de
caminhos são obtidos através de $c$-potenciais. 
Este fato está no lema a seguir, que 
é uma particularização do conhecido lema da dualidade de 
programação linear~\cite{pf:proglin}.

%%%%%%%%%%%%%%%%%%%%%%%%%
%Suponha que $c$ é uma função-custo em $(V,A)$ e que $P$ é um
%caminho de um vértice $s$ a um vértice $t$. Suponha ainda que $y$ é um
%$c$-potencial. Vale que
%\[
%c(P) \geq y(t) - y(s).
%\]
%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{lema}{lema da dualidade}\index{lema!da dualidade}\index{dualidade}
 \label{lema:dualidade}
  Seja $(V,A)$ um grafo e $c$ uma função-custo sobre $V$. 
Para todo caminho $P$ com início em $s$ e término em $t$ e todo $c$-potencial $y$ 
vale que 
\[
c(P) \geq y(t) - y(s). 
\]
\end{lema}

\begin{prova}
Suponha que $P$ é o caminho $\seq{s = v_{0}, \alpha_{1}, v_{1}, \ldots,
  \alpha_{k}, v_{k} = t }$. 
Temos que
\[
\begin{array}{ccl}
 c(P)& =    & c(\alpha_{1}) + \ldots + c (\alpha_{k})\\
     & \geq & (y(v_{1}) - y(v_{0})) + (y(v_{2}) - y(v_{1})) 
              + \ldots + (y(v_{k}) - y(v_{k-1}))\\
     & =    & y(v_{k}) - y(v_{0}) = y(t) - y(s).
\end{array}
\]
\end{prova}

% Se $y$ é uma função-potencial al que $y(s) = 0$, então para cada
% vértice $t$ o valor de $y(t)$ pode ser interpretada como uma distância
% tentativa de $s$ a $t$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A seguir estão dois corolários imediatos do lema da dualidade.
 
% Um conseqüência i
%  \begin{prova}

%  Seja $y$ uma função-potencial viável sobre $V$ e 

%  $P = \seq{s = v_{0}, \alpha_{1}, v_{1}, \ldots, \alpha_{k}, v_{k} = t }$ 
%  um caminho em $(V,A)$.

%  Tem-se que
% \[
% \begin{array}{ccl}
%  c(P)& =    & c_{\alpha_{1}} + \ldots + c_{\alpha_{k}}\\
%      & \geq & y(v_{1}) - y(v_{0}) + y(v_{2}) - y(v_{1}) 
%               + \ldots +y(v_{k}) - y(v_{k-1})\\
%      & =    & y(v_{k}) - y(v_{0}) = y(t) - y(s)
% \end{array}
% \]
% Portanto, $y(t) - y(s) \leq c(P)$.
% \end{prova}
% \end{lema}

 Do lema~\ref{lema:dualidade} tem-se imediatamente os seguintes corolários.

\begin{corolario}{condição de inacessabilidade}%
\index{condicao de@@condição de!inacessabilidade}\index{inacessabilidade}
\label{corolario:inacessabilidade}
Se $(V,A)$ é um grafo, $c$ é uma função-custo, $y$ é um $c$-potencial
 e $s$ e $t$ são vertices tais que 
\[
y(t) - y(s) \geq nC + 1
\]
então, $t$ não é acessível a partir de $s$
\fimprova
\end{corolario}


\begin{corolario}{condição de otimalidade}%
\index{condicao de@@condição de!otimalidade}\index{otimalidade}
\label{corolario:otimalidade}
Seja $(V,A)$ um grafo e $c$ é uma função-custo.
Se $P$ é um caminho de $s$ a $t$ e $y$ é um $c$-potencial tais que 
$y(t) - y(s) = c(P)$, então $P$ é um 
caminho que tem custo mínimo.
\fimprova
\end{corolario}

\begin{figure}
\begin{center}
  \psfrag{0}{\red $1$}
  \psfrag{1}{\red $1$}
  \psfrag{2}{\red $2$}
  \psfrag{3}{\red $3$}
  \psfrag{4}{\red $4$}
  \psfrag{5}{\red $5$}
  \psfrag{6}{\red $6$}
  \psfrag{7}{\red $7$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{c}{$c$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $3$}
  \psfrag{pv}{\blue $5$}
  \psfrag{pu}{\blue $4$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $1$}
  \includegraphics{./figs/potencial-otimo.eps}
\end{center}
\caption{\label{fig:potencial-otimo} Um grafo com custos nos arcos e um 
potencial que certifica que qualquer um dos caminhos com 
arcos em destaque têm custo mínimo.}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO:  FUNÇÃO-PREDECESSOR 
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\section{Representação de caminhos}
\label{sec:predecessor}

Uma maneira compacta de representar caminhos de dado vértice até cada um dos
demais vértices de um grafo é através de uma função-predecessor.
%%% FUNÇÃO-PREDECESSOR 
Uma \defi{função-pre\-de\-ces\-sor}
\index{funcao@@função!predecessor}\index{predecessor!funcao@@função} 
 é uma função ``parcial'' 
$\pred$ de $V$ em $V$ tal que, para cada $v$ em $V\,$,
\[
\pred(v) = \nil \quad \mbox{ou} \quad (\pred(v),v) \in A
\] 


Se $(V,A)$ é um grafo, $\pred$ uma função
predecessor sobre $V$ e $v_{0}, v_{1}, \ldots,v_{k}$ são vértices
tais que
\begin{enumerate}
\item[$\iten{1}$] $ v_{0} = \pred(v_{1}), v_{2} = \pred(v_{3}),
  \ldots, v_{k-1} = \pred(v_{k})$; e
          
\item[$\iten{2}$] $\alpha_{i} := v_{i-1}v_{i}$ está em $A$ para $i =
  1, \ldots, k$.
\end{enumerate}
então dizemos que $\seq{v_{0}, \alpha_{1}, v_{1}, \ldots, \alpha_{k},
v_{k}}$ é um \defi{caminho determinado por
$\pred$}\index{caminho!determinado por $\pred$}. 

Seja $\pred$ uma função-predecessor e $\Psi := \{ uv \in A \tq u =
\pred(v)\}$. Dizemos em $(V,\Psi)$ é o \defi{grafo de
  predecessores}\index{grafo!predecessores}. 

%e que $\psi$
%\defi{determina uma
%  arborescência}\index{arborescencia@@arborescência!determinada por
%  $\pred$} quando o grafo $(V,\Psi)$ é uma arborescência.

Os algoritmos descritos nesta dissertação utilizam funções predecessor para
compactamente representar todos os caminhos de custo mínimo a partir
de um dado vértice. Conforme ilustrado na figura~\ref{fig:pred}.

\begin{figure}[htbp]
 \begin{center}
  \psfrag{0}{$ $}
  \psfrag{1}{$ $}
  \psfrag{2}{$ $}
  \psfrag{3}{$ $}
  \psfrag{4}{$ $}
  \psfrag{5}{$ $}
  \psfrag{6}{$ $}
  \psfrag{7}{$ $}
  \psfrag{8}{$ $}
  \psfrag{9}{$ $}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{$v$}
  \psfrag{u}{$u$}
  \psfrag{w}{$w$}
  \psfrag{z}{$z$}
  \psfrag{TABELA}{
    \begin{tabular}{c ^^7c c}
      vértice & $\pred$ \\ \hline
      $\scor$ & \scor  \\
      $w$      & $s$ \\
      $u$      & $s$ \\
      $\tcor$  & $w$ \\
      $z$      & $w$ \\
      $v$      & $t$ \\
    \end{tabular}
     }
  \includegraphics{./figs/caminho-custo4.eps}
  %\caption[{\sf Representação de caminhos através da função-predecessor}]
  \caption[Representação de caminhos através da função-predecessor]
  {\label{fig:pred} Representação de caminhos através da
    função-predecessor $\pred$ com vértice inicial $\scor$. 
%Os   números próximo aos arcos representam o custo do arco. 
Os arcos
    em destaque formam uma arborecência. A tabela ao lado mostra
    os valores de $\pred$.}
 \end{center}
 \end{figure}

  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: EXAMINANDO UM VÉRTICE
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Examinando arcos e vértices}
\label{sec:examinar}

%%%% Blá inicial
Algoritmos para encontrar caminhos mínimos mantém, tipicamente, além de uma
função-predecessor, uma função-potencial. 
O valor desta função-potencial para cada vértice é um limitante inferior para
o custo dos caminhos que tem como origem o vértice $s$, como mostra 
o lema da dualidade.  
Esta função é
intuitivamente interpretada como uma \defi{distância
  tentativa}\index{distancia@@distância!tentativa} a  partir de $s$. 

%%% Examinar arco
Seja $y$ uma função-potencial e $\pred$ uma função-predecessor.
Uma operação básica envolvendo as funções $\pred$ e $y$ é
\defi{examinar um arco}\index{examinar um/uma!arco}
(\textit{relaxing}~\cite{clrs:introalg-2001},
 \textit{labeling step}~\cite{tarjan:data}). Examinar um arco $uv$ consiste em
 verificar se $y$ respeita  $c$ em $uv$ e, caso não respeite, ou seja,
\[
y(v) - y(u) > c(uv) \ \ \mbox{ou, equivalentemente} \ \ 
y(v) > y(u) + c(uv)
\]
fazer 
\[
y(v) \larr y(u) + c(uv) \ \ \mbox{e} \ \ \pred(v) \larr u.
\]
Intuitivamente, ao  examinar um arco $uv$ tenta-se encontrar um "atalho"
para o caminho de $s$ a $v$ no grafo de predecessores, passando por
$uv$.
O passo de examinar $uv$ pode diminuir o valor da distância
tentativa dos vértices $v$  e atualizar o predecessor, também tentativo,
de $v$ no caminho de custo mínimo de $s$ a $v$. 



\begin{algoritmo}
\ExamineArco{} $(uv)$ \quad $\rhd$ examina o arco $uv$

1 \x \se{} $y(v) > y(u) + c(u,v)$ 


2 \xx \entao\ $y(v) \larr y(u) + c(uv)$ 

3 \xx \phentao{}  $\pred(v) \larr u$
%
%Para cada arco $uv$ tal que $d(v) > d(u) + c(u,v)$ faça \\
%\x $d(v) := d(u) + c(u,v)$ e $\pred(v) := u$. 
\end{algoritmo}


O consumo de tempo para examinar um arco é constante.


%%%% Examinar vértice
Outra operação básica é \defi{examinar um vértice}%
\index{examinar um/uma!vertice@@vértice}. 
Se $u$ é um examinar um consiste em examinar todos os arcos da forma $uv$. Em
linguagem algorítmica tem-se
\begin{algoritmo}
\ExamineVertice{} $(u)$ \quad $\rhd$ examina o vértice $u$

1\x   \para{} \cada{} $uv$ em $A(u)$ \faca{}

2 \xx \ExamineArco{} $(uv)$
%
%Para cada arco $uv$ tal que $d(v) > d(u) + c(u,v)$ faça \\
%\x $d(v) := d(u) + c(u,v)$ e $\pred(v) := u$. 
\end{algoritmo}

ou ainda, de uma maneira expandida

\begin{algoritmo}
\ExamineVertice{} $(u)$ \quad $\rhd$ examina o vértice $u$

1\x   \para{} \cada{} $uv$ em $A(u)$ \faca{}

2 \xx \se{} $y(v) > y(u) + c(uv)$ 


3 \xxx \entao\ $y(v) \larr y(u) + c(uv)$ 

4 \xxx \phentao{}  $\pred(v) \larr u$
%
%Para cada arco $uv$ tal que $d(v) > d(u) + c(u,v)$ faça \\
%\x $d(v) := d(u) + c(u,v)$ e $\pred(v) := u$. 
\end{algoritmo}
O consumo de tempo para examinar um vértice é proporcional ao número de arcos
com ponta inicial no vértice.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: DIJKSTRA 
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algoritmo de Dijsktra}
\label{sec:dijkstra}


Nesta seção é descrito o celebrado algoritmo de
Edsger Wybe Dijkstra~\cite{dijkstra59:note} que resolve o problema do caminho mínimo
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Para cada vértice de $t$ acessível a partir de um dado vértice $s$ o algoritmo
%% de Dijkstra encontra um caminho de $s$ a $t$ que tem custo mínimo.  Da
%% condição de otimalidade (corolário~\ref{corolario:otimalidade}) tem-se que
%% para certificar que um caminho $P$ de $s$ a $t$ tem
%% custo mínimo basta exibir um $c$-pontencial $y$ tal que $c(P)
%% = y(t) - y(s)$. Por outro lado, a condição de inacessabilidade
%% (corolário~\ref{corolario:inacessabilidade}) diz que se $y$ é um $c$-potencial
%% com $y(t) - y(s) = nC + 1$, então $t$ não existe caminho de $s$ a $t$,
%% onde $n$ é o número de vértices do grafo e $C := \max\{c(uv)
%% \tq uv \in A\}$. A correção do algoritmo de Dijkstra
%% fornecerá a recíproca dessas condições.


A idéia geral do algoritmo de Dijkstra para resolver o problema é a seguinte.
O algoritmo é iterativo.  No início de cada iteração tem-se uma partição $S$ e $Q$ 
dos  conjuntos vertices. O algoritmo conhece caminhos de $\scor$ a cada
vértice em $S$ e a uma parte dos vértices em $\Qcor$. Para os vértice em $S$ 
o caminho conhecido tem custo mínimo. Cada iteração consiste em remover um vértice
apropriado de $Q$, incluí-lo $S$ e examiná-lo, atualizando, eventualmente,
o custo dos caminhos a alguns vértices em $Q$.


O algoritmo recebe um grafo $(V,A)$, uma função-custo $c$ de $A$ 
em $\NonnegInt$ e um vértice~$s$ e devolve uma
função-predecessor $\pred$ e uma função-potencial~$y$ que respeita~$c$
tais que, para cada vértice $t$, se $t$ é acessível a partir de $s$, então
$\pred$ determina um caminho de $s$ a $t$ que tem comprimento $y(t) - y(s)$, caso contrário $y(t)-y(s) = nC+1$, 
onde $C := \max\{ c(uv) \tq uv \in A\}.$
Da condição de otimalidade (corolário~\ref{corolario:otimalidade}) tem-se que
$\pred$ determina um caminho de $s$ a um vértice $t$, então este caminho tem custo mínimo.
Por outro lado, a condição de inacessabilidade
(corolário~\ref{corolario:inacessabilidade}) diz que se $y$ é um $c$-potencial
com $y(t) - y(s) = nC + 1$, então não existe caminho de $s$ a $t$.
A correção do algoritmo de Dijkstra
fornecerá a recíproca dessas condições.


A descrição a seguir é a mesma das notas de aula de Feofiloff~\cite{pf:fluxos}.


\begin{algoritmo}
\Dijkstra{} $(V, A, c, \scor)$ \quad {$\rhd$  $c \geq 0$}

1\x \para{} \cada{} $v$ em $V$ \faca

2\xx    $y(v) \larr nC+1$ \quad {$\rhd$  $nC+1$ faz o papel de $\infty$} 

3\xx    $\pred(v) \larr \nil$

4\x  $y(\scor) \larr 0$

5\x $Q \larr N$  \quad {$\rhd$  $Q$ func. como uma fila com
  prioridades} 

6\x \enquanto{} $Q \neq \seq{}$ \faca

7\xx retire de $Q$ um vértice $u$ com $y(u)$ mínimo

%\d7\xx escolha $\icor$ em $\Qcor$ de modo que $\ycor(\icor)$ seja mínimo

%\d8\xx $\Qcor \larr \Qcor - \{\icor\}$ 

8\xx \ExamineVertice~$(u)$

%\d\ph{2}\xxxx {\gray $\rhd$ é possível que $\jcor$ já esteja em $\Qcor$}\\[2mm]
9\x \devolva{} $\pred$ e $y$
\end{algoritmo}


A versão mais expandida é 

\begin{algoritmo}
\Dijkstra{} $(V, A, c, \scor)$ \quad {$\rhd$  $c \geq 0$}

\d1\x \para{} \cada{} $v$ em $V$ \faca

\d2\xx    $y(v) \larr nC+1$ \quad {$\rhd$  $nC+1$ faz o papel de $\infty$} 

\d3\xx    $\pred(v) \larr \nil$

\d4\x  $y(\scor) \larr 0$

\d5\x $Q \larr N$  \quad {$\rhd$  $Q$ func. como uma fila com
  prioridades} 

\d6\x \enquanto{} $Q \neq \seq{}$ \faca

\d7\xx retire de $Q$ um vértice $u$ com $y(u)$ mínimo

%\d7\xx escolha $\icor$ em $\Qcor$ de modo que $\ycor(\icor)$ seja mínimo

%\d8\xx $\Qcor \larr \Qcor - \{\icor\}$ 

\d8\xx \para{} \cada{} $uv$ em $A(u)$ \faca{}

\d9\xxx \se{} $y(v) > y(u) + c(uv)$ \entao{}

10\xxxx $y(v) \larr y(u)+ c(uv) $

11\xxxx $\pred(v) \larr u$

%12\xxxx acrescente $\jcor$ a $\Qcor$ 

%\d\ph{2}\xxxx {\gray $\rhd$ é possível que $\jcor$ já esteja em $\Qcor$}\\[2mm]
12\x \devolva{} $\pred$ e $y$
\end{algoritmo}



\subsection*{Simulação}

A seguir vemos ilustrada a simulação do algoritmo para a chamada
\Dijkstra~$(s)$.  Na figura~(a) vemos o grafo $(V,A)$ dado, onde o número em {\red vermelho} próximo a cada arco indica o seu custo. Por exemplo, $c(tv) = 0$ e $c(sw) = 4$.
Nas ilustrações os vértices com interior azul claro são aqueles que estão em
$Q$. Assim, na figura~(b) vemos que todos os vértices foram inseridos em $Q$.
A função-potencial $y$ é indicada pelos números em {\blue azul} 
próximos cada vértice. Assim, na figura~(b), vemos que $y(\scor)=0$ 
e o potencial dos demais vértices é 
$n \times C + 1 = 6 \times 7 + 1 = 43$.

Durante a simulação, o vértice sendo examinado têm a cor rosa no seu
interior, enquanto o arco sendo examinado é mais espesso e tem a cor
azul.  Por exemplo, na figura~(c) o vértice sendo examinado é $\scor$ e
o arco sendo examinado é $\scor v$.

Os vértices que já foram examinados e, portanto estão em $S$ têm a cor
verde em seu interior. Na figura~(j) vemos que $w$ está sendo examinado, $\scor$ e $u$ são os vértices em $S$ e os demais estão em $\Qcor$.


Os arcos já examinados são espessos e têm a cor vermelha ou são finos e
têm a cor azul escura. Na figura~(k) vemos que o arco $wz$ está sendo
examinado e os arcos já examinados são $\scor v$, $\scor w$, $\scor u$, $u w$, $u z$  
e $wt$.

Os arcos em vermelho são os que formam o grafo de predecessores
com raiz $\scor$. Na figura~(k) os arcos do grafo de predecessores são 
$\scor v$, $\scor u$, $u w$, e  $wt$.
 
\begin{center}
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $ $}
  \psfrag{pt}{\blue $ $}
  \psfrag{pv}{\blue $ $}
  \psfrag{pu}{\blue $ $}
  \psfrag{pw}{\blue $ $}
  \psfrag{pz}{\blue $ $}
  \includegraphics[scale=0.65]{./figs/dijkstra01.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $43$}
  \psfrag{pu}{\blue $43$}
  \psfrag{pw}{\blue $43$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra02.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(a)\hspace*{7cm}(b) 
%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $43$}
  \psfrag{pu}{\blue $43$}
  \psfrag{pw}{\blue $43$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra03.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $43$}
  \psfrag{pw}{\blue $43$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra04.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(c)\hspace*{7cm}(d)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $43$}
  \psfrag{pw}{\blue $4$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra05.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $4$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra06.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(e)\hspace*{7cm}(f)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $4$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra07.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $43$}
  \includegraphics[scale=0.65]{./figs/dijkstra08.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(g)\hspace*{7cm}(h)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $5$}
  \includegraphics[scale=0.65]{./figs/dijkstra09.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $43$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $5$}
  \includegraphics[scale=0.65]{./figs/dijkstra10.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(i)\hspace*{7cm}(j)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $7$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $5$}
  \includegraphics[scale=0.65]{./figs/dijkstra11.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $7$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra12.eps}

 \vspace*{-3mm}
  \hspace*{1cm}(k)\hspace*{7cm}(l)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $7$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra13.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $6$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra14.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(m)\hspace*{7cm}(n)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $6$}
  \psfrag{pv}{\blue $7$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra15.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $6$}
  \psfrag{pv}{\blue $6$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra16.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(o)\hspace*{7cm}(p)

%\end{center}
%\begin{center}

  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $6$}
  \psfrag{pv}{\blue $6$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra17.eps}
  \quad\quad
  \psfrag{0}{\red $0$}
  \psfrag{1}{\red $7$}
  \psfrag{2}{\red $4$}
  \psfrag{3}{\red $2$}
  \psfrag{4}{\red $0$}
  \psfrag{5}{\red $1$}
  \psfrag{6}{\red $1$}
  \psfrag{7}{\red $3$}
  \psfrag{8}{\red $4$}
  \psfrag{9}{\red $1$}
  \psfrag{10}{\red $2$}
  \psfrag{s}{$\scor$}
  \psfrag{t}{$\tcor$}
  \psfrag{v}{\black $v$}
  \psfrag{u}{\black $u$}
  \psfrag{w}{\black $w$}
  \psfrag{z}{\black $z$}
  \psfrag{ps}{\blue $0$}
  \psfrag{pt}{\blue $6$}
  \psfrag{pv}{\blue $6$}
  \psfrag{pu}{\blue $2$}
  \psfrag{pw}{\blue $3$}
  \psfrag{pz}{\blue $4$}
  \includegraphics[scale=0.65]{./figs/dijkstra18.eps}

  \vspace*{-3mm}
  \hspace*{1cm}(q)\hspace*{7cm}(r)
\end{center}





\subsection*{Correção}


A correção do algoritmo de Dijkstra baseia-se nas demonstrações da validade de
uma série de relações invariantes, enunciadas a seguir. 
Estas relações são
afirmações envolvendo os dados do problema $V,A,c$ e $s$ e os objetos $y,
\pred, S$ e $Q$. As afirmações são válidas no início de cada iteração do
algoritmo e dizem como estes objetos se relacionam entre si e com os dados do
problema.


Na linha~6, antes da verificação da condição  ``$Q \neq \seq{}$'' 
valem as seguintes invariantes:
\begin{enumerate}
\item[(dk0)] para cada arco $pq$ no {\red grafo de
    predecessores} tem-se $y(q) - y(p) = c(pq)$;

\item[(dk1)] $\pred(s) = \nil$ e $y(s) = 0$;

\item[(dk2)] para cada vértice $v$ distinto de $s$,
$
yr(v) < n C+1 \Leftrightarrow  pi(v) \neq \nil;
$ 

\item[(dk3)] para cada vértice $v$, se $\pred(v) \neq \nil$ então 
{\red existe} um caminho de $s$ a $v$ no {\red grafo de predecessores}.

\item[(dk4)] para cada arco $pq$ com $y(q) -
  y(p) > c(pq)$ tem-se que $p$~e $q$
  estão~$Q$;

\item[(dk5)] ({\red monotonicidade}) para quaisquer $u$ em $V - Q$,   $v$ em $Q$ vale que
$$y(u) \leq y(v).$$ 
\end{enumerate}



\begin{figure}[htbp]
\begin{center}
  \psfrag{s}{\large $\scor$}
  \psfrag{S}{\large $S$}
  \psfrag{v}{\large $u$}
  \psfrag{Q}{\large $Q$}
  \psfrag{U}{\large $Q$}


\includegraphics[scale=1.2]{./figs/iteracao.eps}


\includegraphics[scale=1.2]{./figs/iteracao1.eps}


\includegraphics[scale=1.2]{./figs/iteracao2.eps}
%  \caption[{\sf Ilustração de uma iteração de \Dijkstra}]
    \caption[Ilustração de uma iteração de \Dijkstra]
  {\label{fig:iteracao} Ilustração de uma iteração do algoritmo \Dijkstra.
    O arcos em vermelho formam o grafo de predecessores. }
\end{center}
\end{figure}

%\item[{\verde (i5)}] se $\Lcor = \seq{\icor_1, \icor_2, \ldots, \icor_{\lcor}}$ estão
%\[
%\ycor(\icor_1) \leq \ycor(\icor_2) \leq \cdots \leq \ycor(\icor_{\lcor});
%\]

\begin{teorema}{da correção}
\label{teorema:correcao}
   Dado um grafo $(V,A)$, uma função
   custo~$c$ e um vértice $s$ o algoritmo \Dijkstra\ corretamente
   encontra um caminho de custo mínimo 
   de $s$ a~$t$, para todo vértice $t$ acessível a partir de $s$.

\end{teorema}


\begin{prova}
%Suponha que no início da última iteração valham as invariantes (dk1) a (dk5).
%Assim temos que, 
Como $\Qcor$ é vazio no início da última iteração, 
então devido a (dk4) a função $y$ é um 
$c$-potencial. Se $y(t) < n C+1$ então, por (dk2), vale que 
$\pred(t) \neq \nil$. Logo, de (dk3), segue  que existe um $st$-caminho $P$ 
no grafo de predecessores. Desta forma, (dk0) e (dk1)  implicam que 
\[
c(P) \geq y(t) - y(s) = y(t).
\]
Da condição de otimalidade, concluímos que $P$ é
um $st$-caminho (de custo) mínimo.

Já, se $y(t) = nC+1$, então 
(dk1) implica que $y(t) - y(s) = nC+1$
e  da condição de inexistência  concluímos que não existe caminho
de $s$ a $t$ no grafo (V,A).

Concluímos portanto que o algoritmo faz o que promete.\fimprova
\end{prova}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: CONSUMO DE TEMPO 
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Consumo de tempo}
\label{sec:consumo-dijkstra}

As duas seguintes operações são as principais responsáveis pelo consumo de
tempo assintótico do algoritmo:
\begin{description}
\item{Escolha de um vértice com potencial mínimo.}  Cada
 execução desta operação gasta tempo $O(n)$.  Como o número de ocorrências do
 caso~2 é no máximo $n$, então o tempo total gasto 
 pelo algoritmo para realizar essa operação é $O(n^{2})$.

\item{Atualização do potencial.} Ao examinar um arco o algoritmo
 eventualmente diminui o pontencial da ponta final. Essa atualização de
potencial é realizada não mais que $^^7c A(u)^^7c$ para examinar o vértice $u$. 
%
%\footnote{conjunto do arcos com ponta inicial em $u$} vezes para  cada
%  vértice $u$ em $V$. 
Ao todo, o algoritmo pode realizar essa operação não mais que 
$\sum_{u \in V} ^^7c A(u) ^^7c = m$ 
vezes. Desde que cada atualização seja feita em tempo constante, o algoritmo
  requer uma quantidade de tempo proporcional a $m$ para atualizar potenciais.
\end{description}


O número de iterações é ${\red < n}$.


\begin{center}
\begin{tabular}{ll}
linha & consumo de {\red todas} as execuções da linha\\
\hline
\rule[0ex]{0ex}{8mm}%
1-3   & $\Oh(n)$\\
4     & $\Oh(1)$ \\
5     & $\Oh(n)$ \\
6     & $n\,\Oh(1) = \Oh(n)$ \\
7     & $n\, \Oh(n) = \Oh(n^2)$ \\
8-11  & $m\,\Oh(1)= \Oh(m)$\\
12    & $\Oh(n)$\\
\hline
\rule[0mm]{0mm}{8mm}%
{\red total} & $\Oh(1) + 4\,\Oh(n) + \Oh(m) + \Oh(n^2)$\\
      & \x   $ = \Oh(n^2)$ 
\end{tabular}
\end{center}


Assim, o consumo de tempo do algoritmo no pior caso é $O(n^{2} + m) = O(n^{2})$.
O teorema abaixo resume a discussão.

\begin{teorema}{consumo de tempo}
\label{teorema:consumo-de-tempo}
O algoritmo \Dijkstra{} quando executado em
um grafo com $n$ vértices e $m$ arcos, consome tempo $O(n^2)$. \fimprova
\end{teorema}
 
Para grafos densos, ou seja, grafos onde $m = \Omega(n^{2})$, o consumo de
tempo de $O(n^{2})$ do algoritmo de Dijkstra é ótimo, pois, é
necessário que todos os arcos do grafo sejam examinados. Entretanto, se $m =
O(n^{2-\epsilon})$ para algum $\epsilon$ positivo, existem métodos
sofisticados, como o heap de Johnson~\cite{johnson:heap}, o fibonacci
heap de Fredman e Tarjan~\cite{FredTarjan:Fibonacci}, que permitem
diminuir o tempo gasto para encontrar um vértice com 
potencial mínimo, gerando assim implementações que consomem menos tempo para
resolver o problema.
   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: FILAS DE PRIORIDADE
%%
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dijkstra e filas de prioridades}

A maneira mais popular para implementar o algoritmo de Dijkstra é
utilizando uma fila de prioridades para representar $\Qcor$, onde a
prioridade de cada vértice $v$ é o seu potencial $y(v)$. A descrição do
algoritmo de Dijkstra logo a seguir faz uso das operações
\BuildMinHeap\, \ExtractMin\ e \DecreaseKey, especificadas na
secão~\ref{sec:filadeprioridade}.

\begin{algoritmo}
{\blue \HeapDijkstra{}} $(V, A, c, s)$ \quad {\gray $\rhd$  $c \geq 0$}

\d1\x \para{} \cada{} $v$ em $V$ \faca

\d2\xx    $y(v) \larr nC+1$ \quad $\rhd$  $nC+1$ faz o papel de $\infty$ 

\d3\xx    $\pred(v) \larr \nil$

\d4\x  $y(s) \larr 0$

\d5\x $Q \larr \BuildMinHeap\,(\Ncor)$  \quad $\rhd$ $Q$ é um min-heap

\d6\x \enquanto{} $Q \neq \seq{}$ \faca

\d7\xx $u \larr \ExtractMin\,(Q)$

\d8\xx \para{} \cada{} $uv$ em $A(u)$ \faca{}

\d9\xxx $\valor \larr y(u) + c(uv)$ 

10\xxx \se{} $y(v) > \valor$ \entao{}

11\xxxx $\DecreaseKey(\valor,v,Q)$

12\xxxx $\pred(u) \larr v$\\[2mm]

%12\xxxx acrescente $\jcor$ a $\Qcor$ 

%\d\ph{2}\xxxx {\gray $\rhd$ é possível que $\jcor$ já esteja em $\Qcor$}\\[2mm]
13\x \devolva{} $\pred$ e $y$
\end{algoritmo}


O número de iterações é ${\red < \ncor}$.


\begin{center}
\begin{tabular}{ll}
linha & consumo de {\red todas} as execuções da linha\\
\hline
\rule[0ex]{0ex}{8mm}%
1-4   & $\Oh(n)$\\
5     & $\Oh(\ncor)$ \\
6     & $\ncor\,\Oh(1) = \Oh(\ncor)$ \\
7     & $\ncor\, \Oh(\lg \ncor) = \Oh(\ncor \lg \ncor)$ \\
8-10  & $\mcor\,\Oh(1)= \Oh(\mcor)$\\
11    & $\mcor\,\Oh(\lg \ncor)= \Oh(\mcor\lg \ncor)$\\
12    & $\mcor\,\Oh(1)= \Oh(\mcor)$\\
13    & $\Oh(\ncor)$\\
\hline
\rule[0mm]{0mm}{8mm}%
{\red total} & $4\,\Oh(\ncor) + 2\, \Oh(\mcor) + \Oh(\ncor \lg \ncor) +
      \Oh(\mcor\, \lg \ncor)$\\
      & \x   $ = \Oh(\mcor \lg \ncor)$ (supondo $(\Ncor,\Acor)$ conexo) 
\end{tabular}
\end{center}




O teorema a seguir resume o número de operação feitas pela
implementação acima para  manipular a fila de
prioridades que representa $Q$.

\begin{teorema}{número de operações}
\label{teorema:no-operacoes}
O algoritmo de Dijkstra, quando executado em um grafo com $n$ vértices e 
$m$ arcos, realiza uma seqüência de $n$ operações \Insert, $n$ 
operações \ExtractMin{}
e no máximo $m$ operações \DecreaseKey. \fimprova
\end{teorema}

O consumo de tempo  do algoritmo Dijkstra
pode variar conforme a implementação de cada uma dessas operações da
fila de prioridade:  \Insert{}, 
\Delete{} e \DecreaseKey{}.

%% O algoritmo de Dijkstra, segundo o teorema~\ref{teorema:no-operacoes}, 
%% realiza uma seqüência de $n$ \Insert{}, $n$ \ExtractMin{} e \Delete{}
%% e no máximo $m$ \DecreaseKey{} operações, em um grafo com $n$
%% vértices e $m$ arcos. Logo, o consumo de tempo  Dijkstra
%% pode variar conforme a implementação de cada uma dessas operações da
%% fila de prioridade.

 % Logo, para melhorar a complexidade desse algoritmo
 %é preciso ``acelerar'' o processo de escolher o vértice com o menor
 %potencial.

 %Uma maneira de se fazer isso é guardar os vértices de maneira organizada, tal
 %que, encontrar o vértice com o menor potencial seja rápido, e ainda 
 %não gaste muito tempo para examinar os arcos. Isso pode ser feito
 %fazendo-se uso da uma fila de prioridade.
 
Existem muitos trabalhos envolvendo implementações de filas de
 prioridade com o intuito de melhorar a complexidade do algoritmo 
de Dijkstra. Para citar alguns exemplos temos
~\cite{ahuja:radixheap, boris:buckets, FredTarjan:Fibonacci}.


 As estruturas de dados utilizadas na implementação das filas de
prioridade podem ser divididas em duas categorias, conforme as
operações elementares utilizadas:
\begin{enumerate}[(1)]
\item (modelo de comparação) estruturas baseadas em comparações; e
\item (modelo RAM) estruturas baseadas em ``bucketing''.
\end{enumerate}

\defi{Bucketing}\index{bucketing} é um método de
 organização dos dados que particiona um conjunto em partes chamadas
 \defi{buckets}\index{bucket}. No que diz respeito ao algoritmo de
 Dijkstra, cada bucket agrupa vértices de um grafo relacionados
 através de prioridades, que nesse caso, são os potenciais.

A tabela a seguir resumo o consumo de tempo de várias implementações de
um min-heap e o respectivo consumo de resultante para o algoritmo de
Dijkstra~\cite{clrs:introalg-2001}.

\footnotesize
\noindent
  \begin{tabular}{^^7cl^^7c^^7cc^^7cc^^7cc^^7cc^^7cc^^7c}\hline
   & heap & \dheap & fibonacci heap & bucket heap & radix heap\\\hline\hline
\BuildMinHeap  & $O(\log n)$& $O(\log_{D} n)$
  &$O(1)$&$O(1)$&$O(\log (nC))$ \\\hline
\textsf{\ExtractMin}  & $O(\log n)$& $O(\log_{D} n)$ &$O(\log n)$&$O(C)$&$O(\log (nC))$\\\hline
\textsf{\DecreaseKey}& $O(\log n)$& $O(\log_{D} n)$ &$O(1)$&$O(1)$&$O(1)$
  \\ \hline \hline
   Dijkstra & $O(m \log n)$ & $O(m\log_{D} n)$ &$O(m + n \log n)$&$O(m
  + nC)$&$O(m +n\log (nC))$ \\ \hline 
  \end{tabular}

\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: CONSUMO DE TEMPO 
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dijkstra e ordenação}
\label{sec:complexidade}

O problema do caminho mínimo, na sua forma mais geral, ou seja, aceitando 
custos negativos, é NP-difícil; o problema do caminho hamiltoniano pode
facilmente ser reduzido a este problema.  
Devido a relação invariante da {\red monotonicidade} {\red (dk5)} tem-se que:
\begin{quote} 
O algoritmo \Dijkstra{} retira os nós da fila $Q$ na linha~7 do algoritmo
em {\red ordem não-decrescente} das suas distância a partir de $\scor$. 
\end{quote}


{\red Conclusão:} o consumo de tempo do algoritmo \Dijkstra{} é~$\Omega(n \log
n)$  


Fredman e Tarjan~\cite{FredTarjan:Fibonacci} observaram que como o algoritmo
de Dijkstra examina os vértices em ordem de distância a partir de $s$
(invariante~\iten{dk3}) então o algoritmo está, implicitamente, ordenando estes
valores. Assim, qualquer implementação do algoritmo de Dijkstra para o modelo comparação adição realiza,
 no pior caso, $\Omega(n \log n)$ comparações. Portanto,
qualquer implementação do algoritmo para o modelo de comparação-adição faz
$\Omega(m + n \log n)$ operações elementares. 
%(ver figura~\ref{fig:liminferior}). 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  SEÇÃO: Implementacao 
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementação de Dijkstra no JUNG}

Como dissemos anteriormente, a biblioteca JUNG contém implementados algoritmos 
para diversos problemas em grafos.
Um desses algoritmos é o desenvolvido por Dikstra para resolver o
 problema do caminho mínimo em grafos sem custos negativos.
Participam da implementação uma série de classes e interfaces que permitem
ao usuário reaproveitar parte do código na criação de versões modificadas do mesmo.

Começaremos pela interface \emph{Distance} cujo objetivo é definir métodos para
 classes que calculam distãncia entre dois vértices.
Possui dois métodos:
\begin{description}
\item[Number getDistance(ArchetypeVertex source, ArchetypeVertex target)]
Responsável por retornar a distância de um caminho ligando o vértice \emph{source} ao \emph{target}. 
O retorno na forma de \emph{Number} 
permite que os tipos númericos: \emph{byte, double, float, int, long e short}, 
sejam usados indistintamente.
Fica a cargo do usuário saber o tipo de dado armazenado para posterior obtenção.
\item[Map getDistanceMap(ArchetypeVertex source)]
Responsável por retornar um mapeamento onde a chave 
representa um vértice acessível a partir do \emph{source} e o valor corresponde 
à distância de um caminho até ele partindo de \emph{source}.
\end{description}

A interface \emph{Distance} é implementada pela classe \emph{DijkstraDistance} cujo objetivo é 
calcular distâncias entre os vértices usando o algortimo de Dijkstra. Além disso, permite que 
resultados parcias, - caminhos e distâncias, sejam armazenados para reutilização posterior.
Descreveremos os seus métodos principais bem como os derivados da interface \emph{Distance}.

Métodos derivados da interface \emph{Distance}:
\begin{description}
\item[Number getDistance(ArchetypeVertex source, ArchetypeVertex target)]
Retorna a distância do menor caminho de \emph{source} a \emph{target}. 
Caso \emph{target} não seja acessível retorna \emph{null}.
\item[Map getDistanceMap(ArchetypeVertex source)]
Retorna o mapeamento como descrito na interface \emph{Distance}, 
com a diferença de que os vértices do mapeamento, quando
percorridos por um \emph{iterator} serão obtidos em 
ordem crescente de distância.
\end{description}

Métodos usados para melhorar o desempenho pelo aplicação de certas restrições:
\begin{description}
\item[LinkedHashMap getDistanceMap(ArchetypeVertex source, int n)]
Subrotina do método \emph{getDistanceMap} cujo objetivo é calcular as distâncias entre o vértice 
\emph{source} e os \emph{n} vértices mais próximos dele, retornando esta informação na forma de um mapeamento, 
como o do método \emph{Map getDistanceMap(ArchetypeVertex source)}.
\item[setMaxDistance(double maxDist)]
Limita a distância máxima para alcançar um vértice no valor de \emph{maxDist}.
Desta maneira, vértices, cujas menores distâncias para serem alcançados a partir de um vértice sejam superiores a \emph{maxDist},
serão considerados inalcançáveis.
\item[setMaxTargets(int maxDestinos)]
Limita o número de vértices cujas distâncias mínimas devam ser calculadas.
Retornando à descrição do algoritmo de Dijkstra da seção 2.5, isto equivale a limitar o 
número de elementos do conjunto $S$ ao valor \emph{maxDestinos}.
\end{description}

O algoritmo de Dijkstra está implementado em duas partes complementares: 
uma rotina iterativa, como a descrita na seção 2.5, e algumas estruturas de dados. 
Como dito anteriormente, o consumo de tempo do algoritmo depende fortemente 
da estrutura de dados utilizada no armazenamento dos vértices ainda não analisados, 
ou seja, no conjunto $Q$.
No JUNG, a estrutura utilizada foi um \emph{heap} binário armazenada na forma de um \emph{array}.
Os principais métodos usados na manipulação de um \emph{heap} estão implementados nas seguintes rotinas:
\begin{description}
\item[add(Object o)]
Insere o objeto \emph{o} no \emph{heap}.
\item[Object pop()]
Retorna e retira o menor elemento do \emph{heap}.
\item[Object peek()]
Apenas retorna o menor elemento.
\item[update(Object o)]
Informa ao \emph{heap} que a chave do elemento \emph{o} foi alterada, de modo que o \emph{heap} precisa ser atualizado.
\end{description}


Para que o \emph{heap} possa ser construído e atualizado é preciso que os seus elementos tenham uma ordenação.
Por isso, a classe \emph{MapBinaryHeap}(nome da classe que implementa a estrutura de \emph{heap} no JUNG), 
possui construtores que permitem definir um \emph{Comparator}  a ser utilizado.
Caso nenhum \emph{comparator} seja passado, utiliza-se o padrão, 
que nada mais faz que tentar comparar os objetos, devendo estes implementarem a interface \emph{Comparable}.
Lembramos que muitas classes do JavaSDK já implementam a interface \emph{Comparable}, 
por exemplo: \emph{Integer, Double, BigInteger}, entre outras.
Assim, poderíamos criar um \emph{heap} com elas sem a necessidade de informar um \emph{Comparator}.


O \emph{heap} no JUNG não é implementado apenas com o uso de um \emph{array}. 
O autor optou por armazenar referências dos objetos contidos no \emph{heap} num \emph{HashMap}, 
onde a chave é o proprio objeto e o valor associado corresponde à posição do objeto no \emph{heap}, permitindo
que o método \emph{update} localize em $\Oh(1)$(consumo de tempo para a localização de um elemento num \emph{hash}) 
a posição no heap do objeto cuja chave fora alterada, para em seguida atualizar o \emph{heap}.

Agora, vamos nos ater ao método principal, aquele que realmente calcula as menores distâncias de uma origem aos outros vértices:

\emph{LinkedHashMap singleSourceShortestPath(ArchetypeVertex source, Set targets, int numDests)}.

O primeiro parâmetro indica o vértice de origem, a parti do qual as distâncias aos demais serão calculadas.
O segundo corresponde a uma lista de vértices de destino. 
Caso a opção de \emph{cache} esteja habilitada, todos os destinos informados ao método, cujas distãncias 
já tenham sido calculadas e armazenadas em chamadas anteriores, serão automaticamente excluídos da lista de 
destinos a serem calculados na chamada corrente.  
Usar ou não \emph{cache} para armazenar resultados previamente calculados é opcional e pode ser definido
tanto nos construtores da classe quanto alterados através do método \emph{enableCaching}.
O seu uso garante melhores desempenhos em chamadas sucessivas para obtenção de diversas distâncias ou 
predecessores, sempre mantendo fixo a origem.
No entanto, vale ressaltar que no caso de alterações do grafo, 
exclusão/adição de arestas e/ou vértices ou até mesmo mudanças 
no comprimento das arestas, podem invalidar as distâncias previamente calculadas, 
sendo que fica a cargo do usuário da classe 
executar uma chamada do método \emph{reset} para que as novas distâncias possam ser retornadas corretamente.
As estruturas de dados utilizadas pelo algoritmo estão centralizadas numa classe chamada \emph{SourceData}.
Os principais dados armazenados são: 
\begin{description}
\item[distances]: Mapeamento contendo as menores distâncias a partir da origem. 
A chave é o vértice e o valor armazenado é a menor distância para alcançá-lo a partir do vértice de origem.
\item[estimatedDistances]: semelhante ao \emph{distances}, com a diferença de guardar a menor distância até o momento, ou seja, 
esta distância pode diminuir.
\item[unknownVertices]: Conjunto de vértices que ainda não foram analisados.
\end{description}
\footnote{Embora haja outros dados, salientamos que ou são auxiliares ou estão relacionados às restrições que visam 
melhorar empiricamente o desempenho do algoritmo e, por isso, serão omitidas na nossa descrição.}
O uso de uma outra classe no armazenamento desses dados permite que as estruturas utilizadas sejam 
alteradas através da especialização da classe \emph{SourceData}. 
Isso será de extrema importância quando estudarmos o algoritmo de geracao de $k$-menores caminhos.
A rotina começa obtendo o \emph{SourceData}, o qual é indexado pelo vértice de origem.
Podem haver tantos quanto o número de vértices do grafo e o seu armazenmaneto em memória entre chamadas sucessivas está vinculado ao 
uso ou não do \emph{cache}.
Caso não exista \emph{SourceData} para o vértice de origem, um novo será criado: as
 estruturas citadas acima são inicializadas, a distância à origem definida como zero e
a origem adicionada a lista \emph{unknowVertices}.
A seguir o funcionamento, \emph{grosso modo}, segue a descrição feita na seção 2.5:
\begin{enumerate}
\item O vértice com menor custo será retirado da lista de vértices não analisados(\emph{unknownVertices}).
\item Para cada aresta partindo dele, a nova distância será comparada com a anteriormente armazenada em \emph{estimatedDistances}.
Se for inferior, o método \emph{update}, da classe \emph{SourceData}, será chamado. 
Caso não exista distância previamente calculada, o método \emph{createRecord} será invocado.
\item Uma vez que todas as arestas de um vértice foram analisadas, este entra na lista de vértices 
cujas distância mínimas já foram calculadas: \emph{distances}.
\end{enumerate}
Ao final, teremos a estrutura \emph{distance} devidamente preenchida, e 
podemos obter as distâncias a partir da origem de todos os vértices alcançáveis.


A classe \emph{DijkstraDistance}, no entanto, não armazena uma lista de predecessores, não permitindo assim 
que caminhos sejam reconstruídos. Para, além de informar distâncias, permitir reconstrução de caminhos, 
o autor especializou a classe \emph{DijkstraDistance}, criando
a classe \emph{DijkstraShortestPath}. As principais mudanças se referem a quatro métodos que foram adicionados:
\begin{description}
\item[Map getIncomingEdgeMap(Vertex origem)]: Retorna um mapeamento indexado pelos vértices acessíveis a partir
do vértice \emph{origem} e, para cada um destes vértices, armazena o correspondente arco incidente 
pertencente ao caminho de custo mínimo até ele. O mapeamento é salvo na forma de um \emph{LinkedHashMap} cuja iteração respeita
o retorno dos vértices com menores custos.
\item[Edge getIncomingEdge(Vertex source, Vertex target)]: Retorna o arco incidente em \emph{target} pertencente ao caminho
de custo mínimo cuja ponta inicial é \emph{source}. Usa o método acima como base.
\item[List getPath(Vertex source, Vertex target)]: Retorna uma lista de arcos que fazem parte do caminho de custo mínimo com ponta final 
\emph{source} e ponta final \emph{target}. A lista encontra-se ordenada de acordo com a ordem e que os arcos aparecem no caminho.
\end{description}

Para que esses métodos pudessem funcionar foi preciso mudar especializar a classe \emph{SourceData}, a qual passou a 
armazenar duas novas estruturas de dados:
\begin{description}
\item[Map tentativeIncomingEdges]: Um mapeamento indexado pelos vértices acessíveis e os seus respectivos 
arcos incidentes pertencente ao caminho de custo mínimo corrente. 
Este arco pode vir a ser substituído caso exista um outro pertencente a um caminho de custo menor que venha a ser calculado
posteriormente. Suas entradas sao alteradas durante a chamada da função \emph{update}.
\item[LinkedHashMap incomingEdges]: Um mapeamento semelhante ao anterior, mas contendo valores definitivos.  	
Uma vez que um vértice é analisado, uma entrada definitiva é criada em \emph{incomingEdges} contendo a entrada
correspondente a este vértice no mapeamento \emph{tentativeIncomingEdges}.
\end{description}

Para maiores detalhes recomendamos a leitura direta do código do JUNG. 




